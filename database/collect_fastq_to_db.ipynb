{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "from collections import defaultdict\n",
    "from igf_data.illumina.samplesheet import SampleSheet\n",
    "import pandas as pd\n",
    "from igf_data.igfdb.igfTables import Base, Experiment, Run\n",
    "from sqlalchemy import create_engine\n",
    "from igf_data.igfdb.baseadaptor import BaseAdaptor\n",
    "from igf_data.igfdb.platformadaptor import PlatformAdaptor\n",
    "from igf_data.igfdb.projectadaptor import ProjectAdaptor\n",
    "from igf_data.igfdb.seqrunadaptor import SeqrunAdaptor\n",
    "from igf_data.igfdb.sampleadaptor import SampleAdaptor\n",
    "from igf_data.igfdb.experimentadaptor import ExperimentAdaptor\n",
    "from igf_data.igfdb.runadaptor import RunAdaptor\n",
    "from igf_data.igfdb.collectionadaptor import CollectionAdaptor\n",
    "from igf_data.igfdb.fileadaptor import FileAdaptor\n",
    "from igf_data.utils.fileutils import calculate_file_checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbparams={'dbname':'../../test_dir/test9_collect_fastq/test.db'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=BaseAdaptor(**dbparams)\n",
    "Base.metadata.drop_all(base.engine)\n",
    "Base.metadata.create_all(base.engine)\n",
    "session_class=base.get_session_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_data=[{'platform_igf_id':'ILM4K_001', \\\n",
    "                'model_name':'HISEQ4000',\\\n",
    "                'vendor_name':'ILLUMINA', \\\n",
    "                'software_name':'RTA', \\\n",
    "                'software_version':'RTA2'},\n",
    "               {'platform_igf_id':'NB501820', \\\n",
    "                'model_name':'NEXTSEQ',\\\n",
    "                'vendor_name':'ILLUMINA', \\\n",
    "                'software_name':'RTA', \\\n",
    "                'software_version':'RTA2'},\n",
    "               {'platform_igf_id':'ILMMS_001', \\\n",
    "                'model_name':'MISEQ',\\\n",
    "                'vendor_name':'ILLUMINA', \\\n",
    "                'software_name':'RTA', \\\n",
    "                'software_version':'RTA1.18.64'},\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl=PlatformAdaptor(**{'session_class':base.session_class})\n",
    "pl.start_session()\n",
    "pl.store_platform_data(data=platform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data=[{'project_igf_id':'ferrer_t2dnoncod-hybcap', \\\n",
    "       'project_name':'ferrer_t2dnoncod-hybcap',  \\\n",
    "       'description':'Its project C', \\\n",
    "       'project_deadline':'Before August 2017', \\\n",
    "       'comments':'Some samples are treated with drug X'}\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa=ProjectAdaptor(**{'session_class':base.session_class})\n",
    "pa.start_session()\n",
    "pa.store_project_and_attribute_data(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=[{'sample_igf_id':'IGF0007142_QXT', \\\n",
    "              'taxon_id':'9606',\\\n",
    "              'scientific_name':'Homo sapiens',\\\n",
    "              'common_name':'human',\\\n",
    "              'donor_anonymized_id':'donor_001',\\\n",
    "              'description':'Sample A from donor 001',\\\n",
    "              'phenotype':'Healthy',\\\n",
    "              'sex':'FEMALE',\\\n",
    "              'project_igf_id':'ferrer_t2dnoncod-hybcap',\\\n",
    "              'sample_tube':'tube001',\\\n",
    "              'sample_library':'IGFS0001_20170628'},\n",
    "             {'sample_igf_id':'IGF0007143_QXT', \\\n",
    "              'taxon_id':'9606',\\\n",
    "              'scientific_name':'Homo sapiens',\\\n",
    "              'common_name':'human',\\\n",
    "              'donor_anonymized_id':'donor_002',\\\n",
    "              'description':'Sample B from donor 002',\\\n",
    "              'phenotype':'Cancer',\\\n",
    "              'sex':'FEMALE',\\\n",
    "              'project_igf_id':'ferrer_t2dnoncod-hybcap',\\\n",
    "              'sample_tube':'tube002',\\\n",
    "              'sample_library':'IGFS0002_20170628'},\n",
    "             {'sample_igf_id':'IGF0007144_QXT', \\\n",
    "              'taxon_id':'9606',\\\n",
    "              'scientific_name':'Homo sapiens',\\\n",
    "              'common_name':'human',\\\n",
    "              'donor_anonymized_id':'donor_002',\\\n",
    "              'description':'Sample B from donor 002',\\\n",
    "              'phenotype':'Cancer',\\\n",
    "              'sex':'FEMALE',\\\n",
    "              'project_igf_id':'ferrer_t2dnoncod-hybcap',\\\n",
    "              'sample_tube':'tube002',\\\n",
    "              'sample_library':'IGFS0002_20170628'},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa=SampleAdaptor(**{'session_class':base.session_class})\n",
    "sa.start_session()\n",
    "sa.store_sample_and_attribute_data(data=sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqrun_data=[{'seqrun_igf_id':'171006_NB501820_0009_AHTGYKAFXX', \n",
    "              'flowcell_id':'HTGYKAFXX', \n",
    "              'platform_igf_id':'NB501820',},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra=SeqrunAdaptor(**{'session_class':base.session_class})\n",
    "sra.start_session()\n",
    "sra.store_seqrun_and_attribute_data(data=seqrun_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesheet_filename='SampleSheet.csv'\n",
    "seqrun_igf_id='171006_NB501820_0009_AHTGYKAFXX'\n",
    "model_name='NEXTSEQ'\n",
    "flowcell_id='HTGYKAFXX'\n",
    "file_location='HPC_PROJECT'\n",
    "fastq_dir='../../test_dir/test9_collect_fastq/nextseq_test/fastq/1_16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fastq_and_samplesheet(fastq_dir, samplesheet_filename):\n",
    "    r1_fastq_regex=re.compile(r'\\S+_R1_\\d+\\.fastq(\\.gz)?', re.IGNORECASE)\n",
    "    r2_fastq_regex=re.compile(r'\\S+_R2_\\d+\\.fastq(\\.gz)?', re.IGNORECASE)\n",
    "    \n",
    "    samplesheet_list=list()\n",
    "    r1_fastq_list=list()\n",
    "    r2_fastq_list=list()\n",
    "    \n",
    "    for root, dirs, files in os.walk(top=fastq_dir, topdown=True):\n",
    "        if samplesheet_filename in files:\n",
    "            samplesheet_list.append(os.path.join(root,samplesheet_filename))\n",
    "        for file in files:\n",
    "            if r1_fastq_regex.match(file):\n",
    "                r1_fastq_list.append(os.path.join(root,file))\n",
    "            elif r2_fastq_regex.match(file):\n",
    "                r2_fastq_list.append(os.path.join(root,file))\n",
    "                \n",
    "    if len(r2_fastq_list) > 0 and len(r1_fastq_list) != len(r2_fastq_list):\n",
    "        raise ValueError('R1 {0} and R2 {1}'.format(len(r1_fastq_list),len(r2_fastq_list)))\n",
    "        \n",
    "    if len(samplesheet_list) > 1:\n",
    "        raise ValueError('Found more than one samplesheet file for fastq dir {0}'.format(fastq_dir))\n",
    "        \n",
    "    return samplesheet_list[0], r1_fastq_list, r2_fastq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_fastq_file_to_sample(sample_name,r1_fastq_list, r2_fastq_list):\n",
    "    sample_files=defaultdict(lambda: defaultdict(lambda: defaultdict()))\n",
    "    r1_regex=re.compile(sample_name+'_S\\d+_L(\\d+)_R1_\\d+\\.fastq(\\.gz)?',re.IGNORECASE)\n",
    "    for file1 in r1_fastq_list:\n",
    "        if r1_regex.match(os.path.basename(file1)):\n",
    "            m=r1_regex.match(os.path.basename(file1))\n",
    "            lane_id=m.group(1).strip('0')\n",
    "            sample_files[lane_id]['R1']=file1\n",
    "            \n",
    "    if len(r2_fastq_list) > 0:\n",
    "        r2_regex=re.compile(sample_name+'_S\\d+_L(\\d+)_R2_\\d+\\.fastq(\\.gz)?',re.IGNORECASE)\n",
    "        for file2 in r2_fastq_list:\n",
    "            if r2_regex.match(os.path.basename(file2)):\n",
    "                m=r2_regex.match(os.path.basename(file2))\n",
    "                lane_id=m.group(1).strip('0')\n",
    "                sample_files[lane_id]['R2']=file2\n",
    "    return sample_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fastq_and_sample_info(fastq_dir,samplesheet_filename,seqrun_igf_id,model_name):\n",
    "    (samplesheet_file, r1_fastq_list, r2_fastq_list)=get_fastq_and_samplesheet(fastq_dir, samplesheet_filename)\n",
    "    samplesheet_data=SampleSheet(infile=samplesheet_file)\n",
    "    fastq_files_list=list()\n",
    "    for row in samplesheet_data._data:\n",
    "        sample_name=row['Sample_Name']\n",
    "        sample_id=row['Sample_ID']\n",
    "        project_name=row['Sample_Project']\n",
    "        description=row['Description']\n",
    "        sample_files=link_fastq_file_to_sample(sample_name,r1_fastq_list, r2_fastq_list)\n",
    "        for lane, lane_files in sample_files.items():\n",
    "            fastq_info={'sample_igf_id':sample_id,\n",
    "                        'sample_name':sample_name,\n",
    "                        'project_igf_id':project_name,\n",
    "                        'lane_number':lane,\n",
    "                        'seqrun_igf_id':seqrun_igf_id,\n",
    "                        'platform_name':model_name,\n",
    "                        'flowcell_id':flowcell_id,\n",
    "                        'description':description\n",
    "                        }\n",
    "            for read_type, filepath in lane_files.items():\n",
    "                fastq_info.update({read_type:filepath})     # allowing only one file per lane per read type\n",
    "            fastq_files_list.append(fastq_info)             # adding entries per samle per lane\n",
    "    return fastq_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_files_list=collect_fastq_and_sample_info(fastq_dir,\\\n",
    "                                               samplesheet_filename,\\\n",
    "                                               seqrun_igf_id,\\\n",
    "                                               model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>description</th>\n",
       "      <th>flowcell_id</th>\n",
       "      <th>lane_number</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>project_igf_id</th>\n",
       "      <th>sample_igf_id</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>seqrun_igf_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../test_dir/test9_collect_fastq/nextseq_tes...</td>\n",
       "      <td>../../test_dir/test9_collect_fastq/nextseq_tes...</td>\n",
       "      <td></td>\n",
       "      <td>HTGYKAFXX</td>\n",
       "      <td>4</td>\n",
       "      <td>NEXTSEQ</td>\n",
       "      <td>ferrer_t2dnoncod-hybcap</td>\n",
       "      <td>IGF0007142_QXT</td>\n",
       "      <td>ctrl_91_H7_MP3913_QXT</td>\n",
       "      <td>171006_NB501820_0009_AHTGYKAFXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../test_dir/test9_collect_fastq/nextseq_tes...</td>\n",
       "      <td>../../test_dir/test9_collect_fastq/nextseq_tes...</td>\n",
       "      <td></td>\n",
       "      <td>HTGYKAFXX</td>\n",
       "      <td>2</td>\n",
       "      <td>NEXTSEQ</td>\n",
       "      <td>ferrer_t2dnoncod-hybcap</td>\n",
       "      <td>IGF0007142_QXT</td>\n",
       "      <td>ctrl_91_H7_MP3913_QXT</td>\n",
       "      <td>171006_NB501820_0009_AHTGYKAFXX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  R1  \\\n",
       "0  ../../test_dir/test9_collect_fastq/nextseq_tes...   \n",
       "1  ../../test_dir/test9_collect_fastq/nextseq_tes...   \n",
       "\n",
       "                                                  R2 description flowcell_id  \\\n",
       "0  ../../test_dir/test9_collect_fastq/nextseq_tes...               HTGYKAFXX   \n",
       "1  ../../test_dir/test9_collect_fastq/nextseq_tes...               HTGYKAFXX   \n",
       "\n",
       "  lane_number platform_name           project_igf_id   sample_igf_id  \\\n",
       "0           4       NEXTSEQ  ferrer_t2dnoncod-hybcap  IGF0007142_QXT   \n",
       "1           2       NEXTSEQ  ferrer_t2dnoncod-hybcap  IGF0007142_QXT   \n",
       "\n",
       "             sample_name                    seqrun_igf_id  \n",
       "0  ctrl_91_H7_MP3913_QXT  171006_NB501820_0009_AHTGYKAFXX  \n",
       "1  ctrl_91_H7_MP3913_QXT  171006_NB501820_0009_AHTGYKAFXX  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fastq_files_list).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_experiment_run_and_file_info(data,restricted_list):\n",
    "    if not isinstance(data, pd.Series):\n",
    "        data=pd.Series(data)\n",
    "        \n",
    "    # set library id\n",
    "    library_id=None\n",
    "    if data.description and data.description not in restricted_list:\n",
    "        library_id=data.description                                    \n",
    "    else:\n",
    "        library_id=data.sample_igf_id                                      \n",
    "    \n",
    "    # calcaulate experiment id\n",
    "    experiment_id='{0}_{1}'.format(library_id,data.platform_name)         \n",
    "    data['library_name']=library_id\n",
    "    data['experiment_igf_id']=experiment_id\n",
    "    # calculate run id\n",
    "    run_igf_id='{0}_{1}_{2}'.format(experiment_id, \\\n",
    "                                    data.flowcell_id, \\\n",
    "                                    data.lane_number)\n",
    "    data['run_igf_id']=run_igf_id\n",
    "    # set collection name and type\n",
    "    data['name']=run_igf_id\n",
    "    data['type']='demultiplexed_fastq'\n",
    "    data['location']='HPC_PROJECT'\n",
    "    # set file md5 and size\n",
    "    if 'R1' in data:\n",
    "      data['R1_md5']=calculate_file_checksum(filepath=data.R1, \\\n",
    "                                             hasher='md5')\n",
    "      data['R1_size']=os.path.getsize(data.R1)\n",
    "    if 'R2' in data:\n",
    "      data['R2_md5']=calculate_file_checksum(filepath=data.R2, \\\n",
    "                                             hasher='md5')\n",
    "      data['R2_size']=os.path.getsize(data.R2)\n",
    "    # set library strategy\n",
    "    library_layout='SINGLE'\n",
    "    if 'R1' in data and 'R2' in data and \\\n",
    "    data.R1 is not None and data.R2 is not None:\n",
    "        library_layout='PAIRED'\n",
    "    data['library_layout']=library_layout\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_file_group_data(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data=data.to_dict(orient='records')\n",
    "        \n",
    "    if not isinstance(data,list):\n",
    "        raise ValueError('Expecting list got {0}'.format(type(data)))\n",
    "        \n",
    "    reformatted_file_group_data=list()\n",
    "    reformatted_file_data=list()\n",
    "\n",
    "    for row in data:\n",
    "      collection_name=None\n",
    "      collection_type=None\n",
    "      file_location=None\n",
    "      if 'name' in row.keys():\n",
    "        collection_name=row['name']\n",
    "      if 'type' in row.keys():\n",
    "        collection_type=row['type']\n",
    "      if 'location' in row.keys():\n",
    "        file_location=row['location']\n",
    "      if 'R1' in row.keys():\n",
    "        r1_file_path=row['R1']\n",
    "        r1_file_size=row['R1_size'] if 'R1_size' in row.keys() else None\n",
    "        r1_file_md5=row['R1_md5'] if 'R1_md5' in row.keys() else None\n",
    "        reformatted_file_data.append({'file_path':r1_file_path,\n",
    "                                      'md5':r1_file_md5,\n",
    "                                      'location':file_location,\n",
    "                                      'size':r1_file_size})\n",
    "        reformatted_file_group_data.append({'name':collection_name,\n",
    "                                            'type':collection_type,\n",
    "                                            'file_path':r1_file_path})\n",
    "      if 'R2' in row.keys():\n",
    "        r2_file_path=row['R2']\n",
    "        r2_file_size=row['R2_size'] if 'R2_size' in row.keys() else None\n",
    "        r2_file_md5=row['R2_md5'] if 'R2_md5' in row.keys() else None\n",
    "        reformatted_file_data.append({'file_path':r2_file_path,\n",
    "                                      'md5':r2_file_md5,\n",
    "                                      'location':file_location,\n",
    "                                      'size':r2_file_size})\n",
    "        reformatted_file_group_data.append({'name':collection_name,\n",
    "                                            'type':collection_type,\n",
    "                                            'file_path':r2_file_path})\n",
    "    return pd.DataFrame(reformatted_file_data), pd.DataFrame(reformatted_file_group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_store_exp_run_and_collection_in_db(session_class,fastq_files_list, restricted_list=['10X']):\n",
    "    dataframe=pd.DataFrame(fastq_files_list)\n",
    "    # calculate additional detail\n",
    "    dataframe=dataframe.apply(lambda data: \\\n",
    "                              calculate_experiment_run_and_file_info(data, \n",
    "                                                                     restricted_list),\\\n",
    "                              axis=1)\n",
    "    # get file data\n",
    "    file_group_columns=['name','type','location',\n",
    "                        'R1','R1_md5','R1_size','R2',\n",
    "                        'R2_md5','R2_size']\n",
    "    file_group_data=dataframe.loc[:,file_group_columns]\n",
    "    file_group_data=file_group_data.drop_duplicates()\n",
    "    (file_data,file_group_data)=reformat_file_group_data(data=file_group_data)\n",
    "    \n",
    "    # get base session\n",
    "    base=BaseAdaptor(**{'session_class':session_class})\n",
    "    base.start_session()\n",
    "    # get experiment data\n",
    "    experiment_columns=base.get_table_columns(table_name=Experiment, \\\n",
    "                                            excluded_columns=['experiment_id', \n",
    "                                                              'project_id', \n",
    "                                                              'sample_id' ])\n",
    "    experiment_columns.extend(['project_igf_id', \n",
    "                               'sample_igf_id'])\n",
    "    exp_data=dataframe.loc[:,experiment_columns]\n",
    "    exp_data=exp_data.drop_duplicates()\n",
    "    # get run data\n",
    "    run_columns=base.get_table_columns(table_name=Run, \\\n",
    "                                       excluded_columns=['run_id', \n",
    "                                                         'seqrun_id', \n",
    "                                                         'experiment_id',\n",
    "                                                         'date_created',\n",
    "                                                         'status'\n",
    "                                                        ])\n",
    "    run_columns.extend(['seqrun_igf_id', \n",
    "                        'experiment_igf_id'])\n",
    "    run_data=dataframe.loc[:,run_columns]\n",
    "    run_data=run_data.drop_duplicates()\n",
    "    \n",
    "    # get collection data\n",
    "    collection_columns=['name',\n",
    "                        'type']\n",
    "    collection_data=dataframe.loc[:,collection_columns]\n",
    "    collection_data=collection_data.drop_duplicates()\n",
    "    \n",
    "    try:\n",
    "      # store experiment to db\n",
    "      ea=ExperimentAdaptor(**{'session':base.session})\n",
    "      ea.store_project_and_attribute_data(data=exp_data,autosave=False)\n",
    "      base.session.flush()\n",
    "      # store run to db\n",
    "      ra=RunAdaptor(**{'session':base.session})\n",
    "      ra.store_run_and_attribute_data(data=run_data,autosave=False)\n",
    "      base.session.flush()\n",
    "      # store file to db\n",
    "      fa=FileAdaptor(**{'session':base.session})\n",
    "      fa.store_file_and_attribute_data(data=file_data,autosave=False)\n",
    "      base.session.flush()\n",
    "      # store collection to db\n",
    "      ca=CollectionAdaptor(**{'session':base.session})\n",
    "      ca.store_collection_and_attribute_data(data=collection_data,\\\n",
    "                                             autosave=False)\n",
    "      base.session.flush()\n",
    "      ca.create_collection_group(data=file_group_data,autosave=False)\n",
    "      base.commit_session()\n",
    "    except:\n",
    "        base.rollback_session()\n",
    "        raise\n",
    "    finally:\n",
    "      base.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_and_store_exp_run_and_collection_in_db(session_class,fastq_files_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
